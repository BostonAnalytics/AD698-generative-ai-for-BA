---
title: "Participation 2: Group Paper Presentation"
subtitle: "Foundations, Architectures, and Responsible Practice in Generative AI"
number-sections: true
date: "2024-11-21"
date-modified: today
date-format: long
bibliography: ../references.bib
csl: ../mis-quarterly.csl
---

## Overview

In this participation assignment, you will work in **groups** to study, synthesize, and present a **foundational or state-of-the-art research paper** in Generative AI, Large Language Models (LLMs), or reproducible computational practice.

The goal is **not** to reproduce the paper technically, but to:

* Understand *why* the paper mattered
* Explain *what problem* it solved
* Situate it within the **modern GenAI stack**
* Critically assess its **assumptions, limitations, and downstream implications**

Each group will deliver a **short academic-style presentation** aimed at a technically literate but non-specialist audience (e.g., analytics managers, graduate students, applied researchers).

This assignment emphasizes:

* Conceptual clarity
* Systems thinking
* Research literacy
* Responsible AI awareness


## Goals

By completing this assignment, you will:

* Develop the ability to **read and interpret AI research papers**
* Learn how modern GenAI systems evolved from earlier computational ideas
* Practice explaining complex ideas clearly and precisely
* Engage critically with **reproducibility, scale, alignment, and responsibility**
* Strengthen academic and professional presentation skills


## Paper Selection (One Paper per Group)

- Everyone must read through the curated list below.
- Papers are organized by **theme**. 
- Each group will need to present a consolidated presentation on papers listed under numbered list.
- Search these papers on scholar.google.com. 


### Open science & reproducibility (classic but still essential) {.unnumbered}

Do not use these for the first presentation. 

- Wilson et al. (2014) *Best Practices for Scientific Computing*
- Peng (2011) *Reproducible Research in Computational Science*
- Stodden et al. (2014) *The Practice of Reproducible Research*
- Stodden et al. (2016) *Computational Reproducibility*
- Knuth (1984) *Literate Programming

## Week 1 - Foundations of Language Representation

| **Neural Foundations**             | **Distributional Semantics**  | **Embeddings in Practice**        |
| ----------------------------------------- | ------------------------------------ | ---------------------------------------- |
| A Neural Probabilistic Language Model [@Bengio2003NeuralLM] | Vector Space Models of Semantics [@TurneyPantel2010VSM] | Distributed Representations of Words [@Mikolov2013Word2Vec] |
|Sequence to sequence learning [@Sutskever2014Sequence]|Are LLMs Models of Distributional Semantics? A Case Study on Quantifiers  [@Enyan2024Distributional]|Efficient Estimation of Word Representations in Vector Space [@Mikolov2013Efficient]|

**Student instruction:** Choose **one column only**. Present how meaning is represented, learned, and operationalized.

## Week 2 – Transformers: Architecture and Attention

| **Transformer Core**                                                        | **Interpretability & Attention**                      | **Representational Power**                                              |
| --------------------------------------------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------- |
| Attention Is All You Need [@Vaswani2017Attention]                           | The Illustrated Transformer [@Alammar2018Illustrated] | On the Computational Power of Transformers [@Perez2019TransformerPower] |
| Sequence to Sequence Learning with Neural Networks [@Sutskever2014Sequence] | What Does BERT Look At? [@Clark2019WhatBERT]          | Are Transformers Universal Approximators? [@Yun2020Transformers]        |

**Student instruction:** Explain *what attention enables* and *what it does not explain*.


## Week 3 – Scaling Laws and Foundation Models

| **Scaling Laws**                                             | **Emergent Abilities**                                           | **Foundation Model Surveys**                                                  |
| ------------------------------------------------------------ | ---------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| Scaling Laws for Neural Language Models [@Kaplan2020Scaling] | Sparks of Artificial General Intelligence [@Bubeck2023SparksAGI] | A Survey of Large Language Models [@Zhao2024LLMSurvey]                        |
| Chinchilla Scaling Laws [@Hoffmann2022Chinchilla]            | Emergent Abilities of LLMs [@Wei2022Emergent]                    | Opportunities and Risks of Foundation Models [@Bommasani2021FoundationModels] |

**Student instruction:** Discuss whether emergence is *real*, *illusory*, or *misinterpreted scaling*.


## Week 4 – Text-as-Data and Business NLP

| **End-to-End NLP Systems**                               | **Enterprise Information Extraction**                                 | **Economic & Policy Text**                             |
| -------------------------------------------------------- | --------------------------------------------------------------------- | ------------------------------------------------------ |
| NLP (Almost) from Scratch [@Collobert2011NLPFromScratch] | Information Extraction from Business Text [@Kogan2019BusinessIE]      | Text as Data [@Gentzkow2019TextAsData]                 |
| A Unified Architecture for NLP [@Collobert2011Unified]   | Measuring Firm-Level Innovation Using Text [@Kelly2021TextInnovation] | ML for Text-Based Economic Research [@Athey2019MLText] |

**Student instruction:** Focus on **organizational value**, not model novelty.


## Week 5 – Prompting, Reasoning, and Orchestration

| **Prompting Taxonomies**                            | **Reasoning via Prompts**                                | **Programmatic Control**           |
| --------------------------------------------------- | -------------------------------------------------------- | ---------------------------------- |
| The Prompt Report [@Schulhoff2025PromptReport]      | Chain-of-Thought Prompting [@Wei2022CoT]                 | DSPy [@Khattab2023DSPy]            |
| Survey of Prompt Engineering [@Liu2023PromptSurvey] | Self-Consistency Improves CoT [@Wang2023SelfConsistency] | Toolformer [@Schick2023Toolformer] |

**Student instruction:** Contrast *prompting as art* vs *prompting as system design*.



## Week 6 – Alignment and Instruction Following

| **Human Feedback Alignment**                                     | **Instruction Tuning**                                   | **Fine-Tuning Systems**                                      |
| ---------------------------------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| Training LMs with Human Feedback [@Ouyang2022RLHF]               | FLAN Instruction Tuning [@Wei2022FLAN]                   | Fine-Tuning from Human Preferences [@Ziegler2019Preferences] |
| Learning to Summarize from Feedback [@Stiennon2020Summarization] | Instruction Tuning with GPT-4 [@Peng2023InstructionGPT4] | Structured Review of LLM Fine-Tuning [@Pratap2025FineTuning] |

**Student instruction:** Treat alignment as a **socio-technical system**, not a loss function.



## Week 7 – Retrieval-Augmented Generation (RAG)

| **Classical RAG**                              | **Failure & Self-Correction**                         | **Hybrid RAG Architectures**           |
| ---------------------------------------------- | ----------------------------------------------------- | -------------------------------------- |
| Retrieval-Augmented Generation [@Lewis2020RAG] | Seven Failure Points in RAG [@Barnett2024RAGFailures] | HybridRAG [@Sarmah2024HybridRAG]       |
| REALM [@Guu2020REALM]                          | Self-RAG [@Asai2023SelfRAG]                           | Corrective RAG [@Yan2024CorrectiveRAG] |

**Student instruction:** Frame RAG as a **reliability and auditability problem**.

## Week 8 – Efficient Fine-Tuning and Small Models

| **Low-Rank Adaptation**     | **Quantization-Aware Tuning** | **Small-Model Ecosystems**                               |
| --------------------------- | ----------------------------- | -------------------------------------------------------- |
| LoRA [@Hu2021LoRA]          | QLoRA [@Dettmers2023QLoRA]    | Survey of Small Language Models [@Nguyen2024SmallLM]     |
| AdaLoRA [@Zhang2023AdaLoRA] | GPTQ [@Frantar2022GPTQ]       | Knowledge Distillation for LLMs [@Hsieh2023Distillation] |

**Student instruction:** Discuss efficiency across **cost, latency, and deployment constraints**.


## Week 9 – Topic Models, Semantic Change, and Clustering

| **Probabilistic Topic Models**                | **Semantic Change**                                      | **Embedding-Based Clustering**                              |
| --------------------------------------------- | -------------------------------------------------------- | ----------------------------------------------------------- |
| Dynamic Topic Models [@Blei2006DynamicTopics] | Diachronic Word Embeddings [@Hamilton2016SemanticChange] | Embedding-Based Clustering Survey [@Aggarwal2022Clustering] |
| Topics over Time [@Wang2006Topics]            | Temporal Word Embeddings [@Kutuzov2018Diachronic]        | BERTopic [@Grootendorst2022BERTopic]                        |

**Student instruction:** Compare **probabilistic vs embedding-based worldviews**.


## Week 10 – Long Context and Multimodality

| **Long Context Limits**                    | **Efficient Context Use**            | **Multimodal Reasoning**              |
| ------------------------------------------ | ------------------------------------ | ------------------------------------- |
| Lost in the Middle [@Liu2023ContextWindow] | LazyLLM [@Xu2024LazyLLM]             | GPT-4V System Card [@OpenAI2023GPT4V] |
| LongNet [@Ding2023LongNet]                 | StreamingLLM [@Xiao2023StreamingLLM] | Segment Anything [@Kirillov2023SAM]   |

**Student instruction:** Explain *why long context fails* and *how models compensate*.


## Week 11 – Evaluation, Hallucination, and Trust

| **Human-Centric Evaluation**                                | **Model-as-Judge**                          | **Hallucination & Risk**                                   |
| ----------------------------------------------------------- | ------------------------------------------- | ---------------------------------------------------------- |
| Evaluating Large Language Models [@Chang2024EvaluatingLLMs] | LLM-as-a-Judge [@Gu2024LLMJudge]            | Survey on Hallucination in LLMs [@Huang2023Hallucinations] |
| Beyond Accuracy [@Gehrmann2023BeyondAccuracy]               | Chain-of-Verification [@Dhuliawala2023CoVe] | Stochastic Parrots [@Bender2021StochasticParrots]          |

**Student instruction:** Debate **whether trust can be automated**.


## Presentation Expectations

### Presentation Length

* **10–12 minutes total**
* **5–7 slides**
* All group members must participate

### Suggested Slide Structure

Your presentation **must include**:

1. **Problem Framing**

   * What problem did this paper address?
   * Why was it important *at the time*?

2. **Core Contribution**

   * Key idea, model, framework, or insight
   * What changed because of this paper?

3. **Technical Intuition (Not Math-Heavy)**

   * Diagrams encouraged
   * Focus on system logic, not equations

4. **Impact and Legacy**

   * How does this paper influence modern GenAI systems?
   * Where do we see it today?

5. **Limitations and Critique**

   * What does the paper *not* address?
   * What assumptions may no longer hold?

6. **Relevance to This Course**

   * How does this connect to:

     * Prompting
     * RAG
     * Fine-tuning
     * Reproducibility
     * Responsible AI


## Submission Requirements

1. **Presentation Slides (PDF)**
2. **One-page Paper Brief (PDF)** including:
   - Paper citation
   - Key contribution (≤150 words)
   - One critique
   - One open research question


## Hints and Best Practices

* Focus on **ideas**, not implementation details
* Assume your audience understands Python and ML basics
* Use diagrams over equations
* Avoid reading slides verbatim
* Practice explaining the paper *without jargon*


This assignment is designed to help you **think like a researcher and systems designer**, not just a tool user.
Choose wisely, read deeply, and present with clarity.

## References

:::{.ref}

:::