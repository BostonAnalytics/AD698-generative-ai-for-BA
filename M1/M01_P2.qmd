---
title: "AD698 - Applied Generative AI"
subtitle: "Language, Probability, and Generative Systems"
logo: "../theme/figures/met_logotype_black.png"
date: 03/12/2024
date-modified: today
date-format: long
author:
  - name: Nakul R. Padalkar
    affiliations:
      - name: Boston University
        city: Boston
        state: MA
format: 
    revealjs:
        theme: [../theme/presentation.scss]
        html-math-method: katex
        slide-number: c/t
        toc: true
        toc-depth: 1
        auto-stretch: false
        from: markdown+emoji
        code-line-numbers: true

    pptx:
        reference-doc: ../theme/presentation_template.pptx
self-contained-math: true
code-annotations: below
fig-align: center
monofont: Roboto
title-slide-attributes:
    data-background-image: "../theme/blank_red.png"
    data-background-size: 103% auto
    data-background-opacity: "0.95"
execute: 
  echo: false
  warning: false
  message: false
  freeze: auto
  keep-ipynb: true
bibliography: ../references.bib
csl: ../mis-quarterly.csl
---

# Text Analytics and Mining

## Text Analytics

![Text Analytics [@talib2016text]](./M01_lecture02_figures/text_mining_overview.jpg){width=80% fig-align="center" #fig-text-mining-overview fig-alt="Text Mining Overview"}

## Text Mining Process

```{dot}
digraph NLP_Pipeline {

    /* =========================
       Global graph settings
       ========================= */

    newrank="true";
    rankdir="TB";
    splines="spline";

    graph [
        fontname="Helvetica"
        fontsize=10
        bgcolor="white"
        ranksep="1.25"
        pad="0.5"
    ];

    node [
        shape="box"
        style="rounded,filled"
        fontname="Helvetica"
        fontsize=11
        color="#1f3a8a"
        fillcolor="#e8f0ff"
    ];

    edge [
        fontname="Helvetica"
        fontsize=9
        color="#1f3a8a"
    ];

    /* =========================
       TOP ROW — Lexical pipeline
       ========================= */

    subgraph cluster_lexical {
        label="Lexical processing";
        style="filled,rounded";
        color="grey95";
        rank=same;

        Characters;
        Tokens;
        TaggedTokens [ label="Tagged tokens" ];

        Characters -> Tokens;
        Tokens -> TaggedTokens;
    }

    /* =========================
       BOTTOM ROW — Structural pipeline
       ========================= */

    subgraph cluster_structural {
        label="Structural representation";
        style="filled,rounded";
        color="grey95";
        rank=same;

        EntityRelations [ label="Entity relationships" ];
        SyntaxTree      [ label="Syntax tree" ];
        KnowledgeBase   [ label="Knowledge base" ];

        /* Right-to-left logical flow */
        SyntaxTree    -> EntityRelations;
        EntityRelations -> KnowledgeBase;

    }
    
    subgraph cluster_algorithm {
        label="Algorithm";
        style="filled,rounded";
        color="grey95";
        rank=same;

        fst_regex[color="#99CC99" fillcolor="#D6EBD6" label="Regular expression" ];
        fst_pos  [color="#99CC99" fillcolor="#D6EBD6" label="Part-of-Speech" ];
        fst_logic[color="#99CC99" fillcolor="#D6EBD6" label="Logic compiler" ];
        fst_ie   [color="#99CC99" fillcolor="#D6EBD6" label="Information extractor" ];
    }

    /* =========================
       Invisible merge anchors
       ========================= */

    merge_tokens [
        shape="circle"
        width=".25"
        fixedsize="true"
        label=""
        style="invis"
    ];

    merge_tagged [
        shape="circle"
        width=".25"
        fixedsize="true"
        label=""
        style="invis"
    ];

    merge_syntax [
        shape="circle"
        width=".25"
        fixedsize="true"
        label=""
        style="invis"
    ];

    /* =========================
       Controlled merges
       ========================= */

    Tokens        -> SyntaxTree      [ arrowhead="vee"];
    TaggedTokens -> SyntaxTree       [ arrowhead="vee"];

    /* =========================
       FST annotations (semantic)
       ========================= */

    /* Invisible anchors for labels */
    // fst_regex  [ shape="circle" width=".25" fixedsize="true" color="invis" label="" ];
    // fst_pos    [ shape="circle" width=".25" fixedsize="true" color="invis" label="" ];
    // fst_logic  [ shape="circle" width=".25" fixedsize="true" color="invis" label="" ];
    // fst_ie     [ shape="circle" width=".25" fixedsize="true" color="invis" label="" ];

    fst_regex -> Tokens       [ style="dashed" arrowhead="vee" constraint="false" color="#99CC99" penwidth=2.0];
    fst_regex -> TaggedTokens [ style="dashed" arrowhead="vee" constraint="false" color="#99CC99" penwidth=2.0];
    SyntaxTree   -> fst_pos [ style="dashed" arrowhead="vee" constraint="false" color="#99CC99" penwidth=2.0];
    KnowledgeBase-> fst_ie    [ style="dashed" arrowhead="vee" constraint="false" color="#99CC99" penwidth=2.0];
    KnowledgeBase-> fst_logic [ style="dashed" arrowhead="vee" constraint="false" color="#99CC99" penwidth=2.0];

    /* Labels */
    // fst_regex  [ xlabel="Regular expressions" ];
    // fst_pos    [ xlabel="POS tagger (FST)" ];
    // fst_logic  [ xlabel="Logic compiler (FST)" ];
    // fst_ie     [ xlabel="Information extractor (FST)" ];

    /* =========================
       Rank alignment
       ========================= */

    { rank="same"; Characters; Tokens; TaggedTokens; }
    { rank="same"; EntityRelations; SyntaxTree; KnowledgeBase; }
    { rank="same"; fst_regex; fst_pos; fst_logic; fst_ie}
}

```

## What is Natural Language Processing (NLP)?

- Technology that enables computers to process, generate, and interact with language (e.g., text). Some key aspects:
- [Learn useful representations]{.uublue-bold}: capture meaning in a structured way that can be used for downstream tasks (e.g., embeddings used to classify a document)
- [Generate language]{.uublue-bold}: create language (e.g., text, 
- code) for tasks like dialogue, translation, or question answering.
- [Bridge language and action]{.uublue-bold}: Use language to perform tasks, solve problems, interact with environments (e.g., a code IDE)

## General NLP Framework 

```{dot}

digraph NLP_Tasks {
  node [shape=plaintext]

  nlp_table [label=<
    <TABLE BORDER="1" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4">
      <TR>
        <TD bgcolor="#137dcb"><B>Input X</B></TD>
        <TD bgcolor="lightcoral"><B>Output Y</B></TD>
        <TD bgcolor="#0ccc90"><B>Task</B></TD>
      </TR>
      <TR>
        <TD>Text</TD>
        <TD>Continuing Text</TD>
        <TD>Language Modeling</TD>
      </TR>
      <TR>
        <TD>Text</TD>
        <TD>Text in Other Language</TD>
        <TD>Translation</TD>
      </TR>
      <TR>
        <TD>Text</TD>
        <TD>Label</TD>
        <TD>Text Classification</TD>
      </TR>
      <TR>
        <TD>Text</TD>
        <TD>Linguistic Structure</TD>
        <TD>Language Analysis</TD>
      </TR>
      <TR>
        <TD>Image</TD>
        <TD>Text</TD>
        <TD>Image Captioning</TD>
      </TR>
    </TABLE>
  >]

  title [label=<
    <TABLE BORDER="0" CELLBORDER="0">
      <TR><TD><B>Create a function to map an input X into an output Y, where X and/or Y involve language.</B></TD></TR>
    </TABLE>
  >]

  title -> nlp_table
}

```

## Building NLP Systems

- Rules: Manual creation of rules

  ```
  def classify(x: str) -> str:
      sports_keywords = ["baseball", "soccer", "football", "tennis"]
      if any(keyword in x for keyword in sports_keywords):
          return "sports"
      else:
          return "other"
  ```


- Prompting: Prompting a language model w/o training

```{dot}
digraph PromptLogic {
  rankdir=LR
  node [shape=plaintext]

  decision_box [label=<
    <TABLE BORDER="0.50" CELLBORDER="0.5" CELLSPACING="0" CELLPADDING="2" bgcolor="lightyellow">
      <TR><TD width="400" fixedsize="false"><B>If the following sentence is about 'sports', reply 'sports'. Otherwise reply 'other'.</B></TD></TR>
    </TABLE>
  >]

  lm_node [label=<
    <TABLE BORDER="1" CELLBORDER="1" CELLSPACING="0" CELLPADDING="2" bgcolor="lightblue">
      <TR><TD width="75" fixedsize="true"><B>LM</B></TD></TR>
    </TABLE>
  >]

  decision_box -> lm_node
}

```

## Building NLP Systems

- Fine-tuning: Machine learning from paired data $\langle X, Y\rangle$

```{dot}
digraph TextClassificationTraining {
    rankdir=LR

  node [shape=plaintext]

  samples [label=<
    <TABLE BORDER="1" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4">
      <TR><TD><B>Sentence</B></TD><TD><B>Label</B></TD></TR>
      <TR><TD>"I love to play baseball."</TD><TD>sports</TD></TR>
      <TR><TD>"The stock price is going up."</TD><TD>other</TD></TR>
      <TR><TD>"He got a hat-trick yesterday."</TD><TD>sports</TD></TR>
      <TR><TD>"He is wearing tennis shoes."</TD><TD>other</TD></TR>
    </TABLE>
  >]

  training [label=<
    <TABLE BORDER="1" CELLBORDER="1" CELLSPACING="0" CELLPADDING="6" bgcolor="lightgray">
      <TR><TD><B>Training</B></TD></TR>
    </TABLE>
  >]

  model [label=<
    <TABLE BORDER="1" CELLBORDER="1" CELLSPACING="0" CELLPADDING="6">
      <TR>
        <TD><IMG SRC="M01_lecture02_figures/reshot-icon-engineering-6XYGVMCJ59.png"/></TD>
        <TD><B>Model</B></TD>
      </TR>
    </TABLE>
  >]

  samples -> training -> model
}

```



## Data Requirements for System Building

-  [Rules/prompting based on intuition]{.uublue-bold}: No data needed, but also no performance guarantees  
- [Rules/prompting based on spot-checks]{.uublue-bold}: A small amount of data with input $X$ only
- [Rules/prompting with rigorous evaluation]{.uublue-bold}: Development set with input $X$ and output $Y$ (e.g. 200-2000 examples). Additional held-out test set also preferable.
- [Fine-tuning]{.uublue-bold}: Additional train set. More is often better - constant accuracy increase when data size doubles.

```{dot}
digraph DataSplit {
  rankdir=LR
  node [shape=plaintext]

  split_table [label=<
    <TABLE BORDER="1" CELLBORDER="1" CELLSPACING="0" CELLPADDING="6">
      <TR>
        <TD bgcolor="lightgreen" width="378">
          <B>Train Data</B><BR/><FONT COLOR="red">X_train, y_train</FONT><BR/>60%
        </TD>
        <TD bgcolor="lightblue" width="108">
          <B>Test Data</B><BR/><FONT COLOR="red">X_test, y_test</FONT><BR/>20%
        </TD>
        <TD bgcolor="lightyellow" width="54">
          <B>Validation (Dev)</B><BR/><FONT COLOR="red">X_val, y_val</FONT><BR/>20%
        </TD>
      </TR>
    </TABLE>
  >]
}

```

## Rule Based Sentiment

:::{.callout-note}
 Given a review ($X$) on a movie ratings website, decide whether its label ($y$) is positive (1), negative (-1) or neutral (0).
:::

```{dot}
digraph SentimentAnalysis {
  rankdir=LR
  node [shape=plaintext, scale=0.60]

  sentence1 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0">
      <TR><TD>"I hate this movie"</TD></TR>
    </TABLE>
  >]

  sentence2 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0">
      <TR><TD>"I love this movie"</TD></TR>
    </TABLE>
  >]

  sentence3 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0">
      <TR><TD>"I saw this movie"</TD></TR>
    </TABLE>
  >]

  sentiment1 [label=<
    <TABLE BORDER="1" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
      <TR>
        <TD><FONT COLOR="red">negative</FONT></TD>
        <TD><FONT COLOR="green">positive</FONT></TD>
        <TD><FONT COLOR="black">neutral</FONT></TD>
      </TR>
    </TABLE>
  >]

  sentiment2 [label=<
    <TABLE BORDER="1" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
      <TR>
        <TD><FONT COLOR="green">positive</FONT></TD>
        <TD><FONT COLOR="black">neutral</FONT></TD>
        <TD><FONT COLOR="red">negative</FONT></TD>
      </TR>
    </TABLE>
  >]

  sentiment3 [label=<
    <TABLE BORDER="1" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
      <TR>
        <TD><FONT COLOR="black">neutral</FONT></TD>
        <TD><FONT COLOR="green">positive</FONT></TD>
        <TD><FONT COLOR="red">negative</FONT></TD>
      </TR>
    </TABLE>
  >]

  sentence1 -> sentiment1
  sentence2 -> sentiment2
  sentence3 -> sentiment3
}

```



# Natural Language Processing Pipeline

## Natural Language Processing Pipeline

![NLP Pipeline](M01_lecture02_figures/NLP-Pipeline.jpeg){width=80% fig-align="center" #fig-nlp-pipeline fig-alt="General NLP Pipeline"}

# Sentiment Classification 

## Text Information

```{python}
# | echo: true
# | eval: true
# | output-location: column

def read_xy_data(filename: str) -> tuple[list[str], list[int]]:
    x_data = []
    y_data = []
    with open(filename, 'r') as f:
        for line in f:
            label, text = line.strip().split(' ||| ')
            x_data.append(text)
            y_data.append(int(label))
    return x_data, y_data


x_train, y_train = read_xy_data('./data/sentiment-treebank/train.txt')
x_test, y_test = read_xy_data('./data/sentiment-treebank/dev.txt')


print("Document:-", x_train[0])
print("Label:-", y_train[0])
```

## Segmentation, Tokenization, and Cleaning

```{python}
# | echo: true
# | eval: true
# | output-location: column

def extract_features(x: str) -> dict[str, float]:
    features = {}
    x_split = x.split(' ')

    # Count the number of "good words" and "bad words" in the text
    good_words = ['love', 'good', 'nice', 'great', 'enjoy', 'enjoyed']  # <1>
    bad_words = ['hate', 'bad', 'terrible',
                 'disappointing', 'sad', 'lost', 'angry']  # <1>
    for x_word in x_split:  # <2>
        if x_word in good_words:  # <2>
            features['good_word_count'] = features.get(
                'good_word_count', 0) + 1  # <2>
        if x_word in bad_words:  # <2>
            features['bad_word_count'] = features.get(
                'bad_word_count', 0) + 1  # <2>

    # The "bias" value is always one, to allow us to assign a "default" score to the text
    features['bias'] = 1  # <3>

    return features


feature_weights = {'good_word_count': 1.0, 'bad_word_count': -1.0, 'bias': 0.5}
```

1. We list the words that represent sentiment,
2. We count the number of good words and bad words in the text,
3. We add a bias term to allow us to assign a "default" score to the text.
   1. Think of $\beta_{0}$ in OLS calculation where we add an array of $[\mathbb{1}]$

## Decision ML Algorithm
```{python}
# | echo: true
# | eval: true
# | output-location: column

def run_classifier(x: str) -> int:
    score = 0
    for feat_name, feat_value in extract_features(x).items():
        score = score + feat_value * feature_weights.get(feat_name, 0)
    if score > 0:
        return 1
    elif score < 0:
        return -1
    else:
        return 0

def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:
    total_number = 0
    correct_number = 0
    for x, y in zip(x_data, y_data):
        y_pred = run_classifier(x)
        total_number += 1
        if y == y_pred:
            correct_number += 1
    return correct_number / float(total_number)


```

## Results 

```{python}
# | echo: true
# | eval: true
# | output-location: column

label_count = {}
for y in y_test:
    if y not in label_count:
        label_count[y] = 0
    label_count[y] += 1
print(label_count)

train_accuracy = calculate_accuracy(x_train, y_train)
test_accuracy = calculate_accuracy(x_test, y_test)

print(f'Train accuracy: {train_accuracy}')
print(f'Dev/test accuracy: {test_accuracy}')

# Display 4 decimal
print(f'Train accuracy: {train_accuracy:.4f}')
print(f'Dev/test accuracy: {test_accuracy:.4f}')

```

## Model Evaluation

```{python}
# | echo: true
# | eval: true
# | output-location: column

import random


def find_errors(x_data, y_data):
    error_ids = []
    y_preds = []
    for i, (x, y) in enumerate(zip(x_data, y_data)):
        y_preds.append(run_classifier(x))
        if y != y_preds[-1]:
            error_ids.append(i)
    for _ in range(5):
        my_id = random.choice(error_ids)
        x, y, y_pred = x_data[my_id], y_data[my_id], y_preds[my_id]
        print(f'{x}\ntrue label: {y}\npredicted label: {y_pred}\n')


find_errors(x_train, y_train)

```

## Improving the Model

1. What's going wrong with my system?
2. Modify the system (featurization, scoring function, etc.)
3. Measure accuracy improvements, accept/reject change
4. Repeat from 1
5. Finally, when satisfied with dev accuracy, evaluate on test

# Extreme or Rare Cases

## Linguistic Barriers

- Low-frequency Words
- Conjugation
- Negation 
- Metaphor 
- Analogy
- Symbolic Languages

:::{.callout-tip}
Can we think of solutions for these?
:::


# Probabilistic Topic Modeling 

## Probabilistic Topic Modeling {background-color="#f6e1d7"}

![Probabilistic Topic Modeling](M01_lecture02_figures/Probabilistic-Topic-Modeling.png){width=80% fig-align="center" #fig-topic-modeling fig-alt="screenshot of papers from Science magazine about topic modeling"}

## Machine Learning
-  We want to [estimate]{.uugreen-bold} a function that will [predict]{.uugreen-bold} the label of a given text relatively well.
- The function $f(x)$ can be [linear]{.uugreen-bold} or [non-linear]{.uugreen-bold}.
- It can be [defined by humans]{.uugreen-bold} or [learned from data]{.uugreen-bold}.

![Machine Learning](M01_lecture02_figures/MLsteps.png){width=80% fig-align="center" #fig-machine-learning fig-alt="Machine Learning end to end pipeline"}

# Bag of Words approach

## What is Bag of Words?

- Text is treated as a **collection (bag)** of words
- Word order is discarded
- Each document becomes a **vector of word counts**

![Bag of Words](M01_lecture02_figures/bag-of-words.png){width=60% fig-align="center" #fig-bag-of-words fig-alt="Bag of Words"}

## Why We Need Bag of Words

- Machines do not understand text
- Models require **fixed-length numeric vectors**
- Bag of Words is the **first workable bridge** between language and math

> "Meaning is ignored; frequency is preserved."

---

## Text Cleaning

::: {.columns}
::: {.column width="50%" .fragment}
:::{.callout}
Despite suffering a sense-of-humour failure , The Man Who Wrote Rocky does not deserve to go down with a ship as leaky as this .
:::

:::{.callout}
despite suffering a sense of humour failure the man who wrote rocky does not deserve to go down with a ship as leaky as this
:::

:::
::: {.column width="50%" .fragment}

- Lowercasing
- Removing punctuation
- Removing numbers
- Removing stopwords (optional)
:::
:::

---

## Stanford Text Corpus Import

```{python}
# | echo: true
# | eval: true
# | output-location: column

import random

def sample_sentences(x, y, n=4, seed=42):
    random.seed(seed)
    idx = random.sample(range(len(x)), n)
    return [(y[i], x[i]) for i in idx]

samples = sample_sentences(x_train, y_train, n=4)

for i, (label, text) in enumerate(samples, 1):
    print(f"S{i} [label={label}]: {text}")

```

- Import all documents in the corpus.
- Make sure they are stored in the right format.

## Tokenization

- Breaking text into units
  - Split text into tokens (usually words)
  - Simple whitespace tokenization is often enough
  - More advanced methods exist (e.g., subword tokenization)
  - Tokens are the **building blocks** for Bag of Words
  - Example:  "I love NLP!"  $\rightarrow$  ["I", "love", "NLP"]

---

## Building `CountVectorizer`

```{python}
# | echo: true
# | eval: true
# | output-location: column

from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd

docs = [text for _, text in samples]

vectorizer = CountVectorizer(
    lowercase=True,
    stop_words=None   # keep everything for teaching clarity
)

X = vectorizer.fit_transform(docs)

bow_df = pd.DataFrame(
    X.toarray(),
    columns=vectorizer.get_feature_names_out(),
    index=[f"S{i+1}" for i in range(len(docs))]
)

bow_df.iloc[:, 0:8]

```

## Vocabulary Construction

- Vocabulary = **unique words across all documents**
- Vocabulary size grows quickly
- Rare words may be removed
- Vocabulary ≈ **feature space**
- Too large → sparse, inefficient models

## Counting Words - Document-Term Matrix (DTM)

- Rows = documents
- Columns = vocabulary terms
- Values = word counts

This is the [actual model input]{.uublue-bold}.

## Word Frequencies

```{python}
#| echo: false
#| eval: true
#| 

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sum word counts across all sampled documents
term_frequencies = bow_df.sum(axis=0)

# Select top 15 terms
top_terms = term_frequencies.sort_values(ascending=False).head(15)

# Drop words below 3 letters for clarity
top_terms_3 = top_terms[top_terms.index.str.len() >= 3]

# ---------------------------------------------------------
# 1. Prepare data for grouped barplot
# ---------------------------------------------------------

df_plot = pd.DataFrame({
    "term": top_terms.index,
    "count_top15": top_terms.values,
    "count_top15_3": top_terms_3.reindex(top_terms.index, fill_value=0).values
})

df_melt = df_plot.melt(
    id_vars="term",
    value_vars=["count_top15", "count_top15_3"],
    var_name="category",
    value_name="count"
)

df_melt["category"] = df_melt["category"].map({
    "count_top15": "Top 15 Terms",
    "count_top15_3": "Top Terms (≥3 letters)"
})

# ---------------------------------------------------------
# 2. Global styling
# ---------------------------------------------------------

plt.rcParams["font.family"] = "Roboto"
plt.rcParams["axes.titleweight"] = "bold"
plt.rcParams["axes.labelweight"] = "bold"

sns.set_theme(style="white")

# ---------------------------------------------------------
# 3. Plot
# ---------------------------------------------------------
plt.figure(figsize=(10, 5.5))

ax = sns.barplot(
    data=df_melt,
    x="term",
    y="count",
    hue="category",
    palette=sns.color_palette("dark", n_colors=2),
    alpha=0.6 #
)

# Title: bold, left-aligned, 14 pt
plt.title("Comparison of Top Terms vs. Top Terms (≥3 letters)",
          fontsize=14, fontweight="bold", loc="left")

# Axis labels bold
plt.xlabel("Term", fontsize=12, fontweight="bold")
plt.ylabel("Word Count", fontsize=12, fontweight="bold")

plt.xticks(rotation=45, ha="right", fontsize=11)

# Legend outside top-right
plt.legend(
    title="",
    fontsize=12,
    loc="upper right",           # anchor to top-right corner
    bbox_to_anchor=(1, 1),       # position inside plot
    ncol=2,                      # horizontal layout
    borderaxespad=0.2,           # slight padding
    frameon=False                # optional: remove legend box
)

plt.tight_layout()
plt.show()

```


---

## What BoW Gets Right

::: {.columns}
::: {.column}
### Strengths

- Simple and interpretable
- Fast to compute
- Works surprisingly well for:
  - sentiment analysis
  - topic classification
  - spam detection


:::
::: {.column}
### Limitations

- Ignores word order
- Ignores meaning
- Vocabulary explosion
- Sparse matrices
- Classic failure: "not good" ≈ "good"

:::
:::

---



## BoW in Practice (Sentiment Analysis)

```{dot}
digraph SentimentPipeline {

    rankdir=LR;
    splines=ortho;
    bgcolor="white";
    nodesep=0.6;
    ranksep=0.9;
    fontname="Helvetica";

    node [
        shape=box,
        style="rounded,filled",
        fontname="Helvetica",
        fontsize=10,
        fillcolor="#F7F7F7",
        color="#555555"
    ];

    edge [
        fontname="Helvetica",
        fontsize=9,
        color="#555555"
    ];

    /* ===== Input Layer ===== */
    Text [
        label="Textual Data\n(A statement)",
        fillcolor="#E8F1FA"
    ];

    /* ===== Lexicons ===== */
    Lex1 [
        label="Corpus",
        shape=folder,
        fillcolor="#FFF3CD"
    ];

    Lex2 [
        label="Lexicon",
        shape=cylinder,
        fillcolor="#FFF3CD"
    ];

    /* ===== Processing Steps ===== */
    Step1 [
        label="Step 1:\nCalculate O–S Polarity",
        fillcolor="#E3F2FD"
    ];

    Decision [
        label="Is there a sentiment?",
        shape=diamond,
        fillcolor="#FDEDEC"
    ];

    Step2 [
        label="Step 2:\nCalculate N–P Polarity\nof the sentiment",
        fillcolor="#E3F2FD"
    ];

    Step3 [
        label="Step 3:\nIdentify the target\nfor the sentiment",
        fillcolor="#E3F2FD"
    ];

    /* ===== Output Layer ===== */
    Record [
        label="Record Polarity,\nStrength,\nand Target",
        fillcolor="#E8F8F5"
    ];

    Step4 [
        label="Step 4:\nTabulate & aggregate\nsentiment analysis results",
        fillcolor="#D5F5E3"
    ];

    /* ===== Layout Control (Two Rows) ===== */
    { rank=same; Text; Step1; Decision }
    { rank=same; Step2; Step3; Record; Step4 }

    /* ===== Edges ===== */
    Text -> Step1;
    Lex1 -> Step1;

    Step1 -> Decision;

    Decision -> Text   [label="No"];
    Decision -> Step2  [label="Yes"];

    Lex2 -> Step2;

    Step2 -> Step3;

    Step1 -> Record [label="O–S Polarity"];
    Step2 -> Record [label="N–P Polarity"];
    Step3 -> Record [label="Target"];

    Record -> Step4;
}

```


---

## When Should You Use BoW?

::: {.columns}
::: {.column}
### When to Use Bag of Words
-  Dataset is small to medium
-  Interpretability matters
-  You need a fast baseline
-  Text is short and structured
:::
::: {.column}
### When Not to Use Bag of Words
- Long documents
- Semantic nuance matters
- Context is critical

:::
:::
---

## Conceptual Takeaway

**One sentence slide**

> Bag of Words is not about language—it is about **counting**.

This prepares students mentally for:

* TF-IDF (weighting counts)
* Embeddings (learning meaning)
* Transformers (learning context)



# References

:::{.refs}

:::