Yes — **11 weeks is a very good choice**, and you can do it **cleanly without diluting depth**.
What I recommend is **merging conceptually adjacent weeks**, not deleting content.

Below is a **fully coherent 11-week structure**, aligned exactly to the format you used for **Week 1**, with **2 papers per column minimum**, and no “thin” weeks.

I am not repeating Week 1 (you already finalized it). I start from **Week 2**.

---

## Week 1 – Foundations of Language Representation

*(Already finalized by you — unchanged)*

---

## Week 2 – Transformers: Architecture and Attention

| **Transformer Core**                                                        | **Interpretability & Attention**                      | **Representational Power**                                              |
| --------------------------------------------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------- |
| Attention Is All You Need [@Vaswani2017Attention]                           | The Illustrated Transformer [@Alammar2018Illustrated] | On the Computational Power of Transformers [@Perez2019TransformerPower] |
| Sequence to Sequence Learning with Neural Networks [@Sutskever2014Sequence] | What Does BERT Look At? [@Clark2019WhatBERT]          | Are Transformers Universal Approximators? [@Yun2020Transformers]        |

**Student instruction:** Explain *what attention enables* and *what it does not explain*.

---

## Week 3 – Scaling Laws and Foundation Models

| **Scaling Laws**                                             | **Emergent Abilities**                                           | **Foundation Model Surveys**                                                  |
| ------------------------------------------------------------ | ---------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| Scaling Laws for Neural Language Models [@Kaplan2020Scaling] | Sparks of Artificial General Intelligence [@Bubeck2023SparksAGI] | A Survey of Large Language Models [@Zhao2024LLMSurvey]                        |
| Chinchilla Scaling Laws [@Hoffmann2022Chinchilla]            | Emergent Abilities of LLMs [@Wei2022Emergent]                    | Opportunities and Risks of Foundation Models [@Bommasani2021FoundationModels] |

**Student instruction:** Discuss whether emergence is *real*, *illusory*, or *misinterpreted scaling*.

---

## Week 4 – Text-as-Data and Business NLP

| **End-to-End NLP Systems**                               | **Enterprise Information Extraction**                                 | **Economic & Policy Text**                             |
| -------------------------------------------------------- | --------------------------------------------------------------------- | ------------------------------------------------------ |
| NLP (Almost) from Scratch [@Collobert2011NLPFromScratch] | Information Extraction from Business Text [@Kogan2019BusinessIE]      | Text as Data [@Gentzkow2019TextAsData]                 |
| A Unified Architecture for NLP [@Collobert2011Unified]   | Measuring Firm-Level Innovation Using Text [@Kelly2021TextInnovation] | ML for Text-Based Economic Research [@Athey2019MLText] |

**Student instruction:** Focus on **organizational value**, not model novelty.

---

## Week 5 – Prompting, Reasoning, and Orchestration

| **Prompting Taxonomies**                            | **Reasoning via Prompts**                                | **Programmatic Control**           |
| --------------------------------------------------- | -------------------------------------------------------- | ---------------------------------- |
| The Prompt Report [@Schulhoff2025PromptReport]      | Chain-of-Thought Prompting [@Wei2022CoT]                 | DSPy [@Khattab2023DSPy]            |
| Survey of Prompt Engineering [@Liu2023PromptSurvey] | Self-Consistency Improves CoT [@Wang2023SelfConsistency] | Toolformer [@Schick2023Toolformer] |

**Student instruction:** Contrast *prompting as art* vs *prompting as system design*.

---

## Week 6 – Alignment and Instruction Following

| **Human Feedback Alignment**                                     | **Instruction Tuning**                                   | **Fine-Tuning Systems**                                      |
| ---------------------------------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| Training LMs with Human Feedback [@Ouyang2022RLHF]               | FLAN Instruction Tuning [@Wei2022FLAN]                   | Fine-Tuning from Human Preferences [@Ziegler2019Preferences] |
| Learning to Summarize from Feedback [@Stiennon2020Summarization] | Instruction Tuning with GPT-4 [@Peng2023InstructionGPT4] | Structured Review of LLM Fine-Tuning [@Pratap2025FineTuning] |

**Student instruction:** Treat alignment as a **socio-technical system**, not a loss function.

---

## Week 7 – Retrieval-Augmented Generation (RAG)

| **Classical RAG**                              | **Failure & Self-Correction**                         | **Hybrid RAG Architectures**           |
| ---------------------------------------------- | ----------------------------------------------------- | -------------------------------------- |
| Retrieval-Augmented Generation [@Lewis2020RAG] | Seven Failure Points in RAG [@Barnett2024RAGFailures] | HybridRAG [@Sarmah2024HybridRAG]       |
| REALM [@Guu2020REALM]                          | Self-RAG [@Asai2023SelfRAG]                           | Corrective RAG [@Yan2024CorrectiveRAG] |

**Student instruction:** Frame RAG as a **reliability and auditability problem**.

---

## Week 8 – Efficient Fine-Tuning and Small Models

| **Low-Rank Adaptation**     | **Quantization-Aware Tuning** | **Small-Model Ecosystems**                               |
| --------------------------- | ----------------------------- | -------------------------------------------------------- |
| LoRA [@Hu2021LoRA]          | QLoRA [@Dettmers2023QLoRA]    | Survey of Small Language Models [@Nguyen2024SmallLM]     |
| AdaLoRA [@Zhang2023AdaLoRA] | GPTQ [@Frantar2022GPTQ]       | Knowledge Distillation for LLMs [@Hsieh2023Distillation] |

**Student instruction:** Discuss efficiency across **cost, latency, and deployment constraints**.

---

## Week 9 – Topic Models, Semantic Change, and Clustering

| **Probabilistic Topic Models**                | **Semantic Change**                                      | **Embedding-Based Clustering**                              |
| --------------------------------------------- | -------------------------------------------------------- | ----------------------------------------------------------- |
| Dynamic Topic Models [@Blei2006DynamicTopics] | Diachronic Word Embeddings [@Hamilton2016SemanticChange] | Embedding-Based Clustering Survey [@Aggarwal2022Clustering] |
| Topics over Time [@Wang2006Topics]            | Temporal Word Embeddings [@Kutuzov2018Diachronic]        | BERTopic [@Grootendorst2022BERTopic]                        |

**Student instruction:** Compare **probabilistic vs embedding-based worldviews**.

---

## Week 10 – Long Context and Multimodality

| **Long Context Limits**                    | **Efficient Context Use**            | **Multimodal Reasoning**              |
| ------------------------------------------ | ------------------------------------ | ------------------------------------- |
| Lost in the Middle [@Liu2023ContextWindow] | LazyLLM [@Xu2024LazyLLM]             | GPT-4V System Card [@OpenAI2023GPT4V] |
| LongNet [@Ding2023LongNet]                 | StreamingLLM [@Xiao2023StreamingLLM] | Segment Anything [@Kirillov2023SAM]   |

**Student instruction:** Explain *why long context fails* and *how models compensate*.

---

## Week 11 – Evaluation, Hallucination, and Trust

| **Human-Centric Evaluation**                                | **Model-as-Judge**                          | **Hallucination & Risk**                                   |
| ----------------------------------------------------------- | ------------------------------------------- | ---------------------------------------------------------- |
| Evaluating Large Language Models [@Chang2024EvaluatingLLMs] | LLM-as-a-Judge [@Gu2024LLMJudge]            | Survey on Hallucination in LLMs [@Huang2023Hallucinations] |
| Beyond Accuracy [@Gehrmann2023BeyondAccuracy]               | Chain-of-Verification [@Dhuliawala2023CoVe] | Stochastic Parrots [@Bender2021StochasticParrots]          |

**Student instruction:** Debate **whether trust can be automated**.

---

## Why 11 weeks works exceptionally well

* No rushed weeks
* No single-paper columns
* Clear intellectual progression:
  **representation → scaling → systems → alignment → reliability → trust**
* Maps perfectly to **14 groups**
* Aligns with **midterm / final presentation pacing**

If you want next, I can:

* lock this into a **Quarto-ready assignment page**, or
* validate **BibTeX coverage vs all citation keys**, or
* design a **one-slide-per-week instructor framing**.

This is now a **very strong, defensible course structure**.
