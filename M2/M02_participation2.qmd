---
title: "Participation 2: Group Paper Presentation"
subtitle: "Foundations, Architectures, and Responsible Practice in Generative AI"
number-sections: true
date: "2024-11-21"
date-modified: today
date-format: long
---

## Overview

In this participation assignment, you will work in **groups** to study, synthesize, and present a **foundational or state-of-the-art research paper** in Generative AI, Large Language Models (LLMs), or reproducible computational practice.

The goal is **not** to reproduce the paper technically, but to:

* Understand *why* the paper mattered
* Explain *what problem* it solved
* Situate it within the **modern GenAI stack**
* Critically assess its **assumptions, limitations, and downstream implications**

Each group will deliver a **short academic-style presentation** aimed at a technically literate but non-specialist audience (e.g., analytics managers, graduate students, applied researchers).

This assignment emphasizes:

* Conceptual clarity
* Systems thinking
* Research literacy
* Responsible AI awareness


## Goals

By completing this assignment, you will:

* Develop the ability to **read and interpret AI research papers**
* Learn how modern GenAI systems evolved from earlier computational ideas
* Practice explaining complex ideas clearly and precisely
* Engage critically with **reproducibility, scale, alignment, and responsibility**
* Strengthen academic and professional presentation skills


## Paper Selection (One Paper per Group)

- Everyone must read through the curated list below.
- Papers are organized by **theme**. 
- Each group will need to present a consolidated presentation on papers listed under numbered list.
- Search these papers on scholar.google.com. 


### Open science & reproducibility (classic but still essential) {.unnumbered}

Do not use these for the first presentation. 

- Wilson et al. (2014) *Best Practices for Scientific Computing*
- Peng (2011) *Reproducible Research in Computational Science*
- Stodden et al. (2014) *The Practice of Reproducible Research*
- Stodden et al. (2016) *Computational Reproducibility*
- Knuth (1984) *Literate Programming

### Foundations of language representations

- Bengio et al. (2003) *A Neural Probabilistic Language Model*
- Turney & Pantel (2010) *Vector Space Models of Semantics*
- Mikolov et al. (2013) *Word2Vec / Distributed Representations*

### Transformers + scaling

- Vaswani et al. (2017) *Attention Is All You Need*
- Alammar *The Illustrated Transformer*
- Kaplan et al. (2020) *Scaling Laws for Neural Language Models*
- Zhao et al. (2024) *Survey of Large Language Models*

### Text-as-data & business NLP

- Collobert et al. (2011) *NLP (Almost) from Scratch*
- Kogan et al. (2019) *Information Extraction from Business Text*

### Prompting & orchestration

- Schulhoff et al. (2025) *The Prompt Report*
- Wei et al. (2022) *Chain-of-Thought Prompting*
- Khattab et al. (2023) *DSPy framework paper*

### Alignment & instruction following

- Ouyang et al. (2022) *Training Language Models with Human Feedback*
- Peng et al. (2023) *Instruction tuning with GPT-4*
- Pratap et al. (2025) *The fine art of fine-tuning: A structured review of advanced LLM fine-tuning techniques*

### RAG & reliability engineering

- Lewis et al. (2020) *Retrieval-Augmented Generation*
- Barnett et al. (2024) *Seven Failure Points When Engineering a RAG System*
- Asai et al. (2023) *Self-RAG*

### RAG & reliability engineering

- Yan et al. (2024) *Corrective RAG (CRAG)*
- Sarmah et al. (2024) *HybridRAG*

### Efficient finetuning + small models

- Hu et al. (2021) *LoRA*
- Dettmers et al. (2023) *QLoRA*
- Nguyen et al. (2024) Survey on small language models 

### Topic models, semantic change, clustering

- Blei & Lafferty (2006) *Dynamic Topic Models*
- Embedding-based document clustering survey
- Semantic change detection in text

### Long context & multimodality

- Liu et al. (2023) *Context window evaluation*
- LongNet
- LazyLLM

### Long context & multimodality

- GPT-4V technical report (OpenAI)
- Segment Anything (Meta)
- Multimodal chain-of-thought reasoning

### Evaluation

- Evaluating LLMs survey
- LLM-as-a-judge survey (e.g., Gu et al., 2024)
- Dhuliawala et al. (2023/2024) *Chain-of-Verification*

### Hallucinations

- Huang et al. (2023) *Survey on Hallucination in LLMs*
- Bender et al. (2021) *Hallucination: Stochastic Parrots*

## Presentation Expectations

### Presentation Length

* **10–12 minutes total**
* **5–7 slides**
* All group members must participate

### Suggested Slide Structure

Your presentation **must include**:

1. **Problem Framing**

   * What problem did this paper address?
   * Why was it important *at the time*?

2. **Core Contribution**

   * Key idea, model, framework, or insight
   * What changed because of this paper?

3. **Technical Intuition (Not Math-Heavy)**

   * Diagrams encouraged
   * Focus on system logic, not equations

4. **Impact and Legacy**

   * How does this paper influence modern GenAI systems?
   * Where do we see it today?

5. **Limitations and Critique**

   * What does the paper *not* address?
   * What assumptions may no longer hold?

6. **Relevance to This Course**

   * How does this connect to:

     * Prompting
     * RAG
     * Fine-tuning
     * Reproducibility
     * Responsible AI


## Submission Requirements

1. **Presentation Slides (PDF)**
2. **One-page Paper Brief (PDF)** including:
   - Paper citation
   - Key contribution (≤150 words)
   - One critique
   - One open research question


## Hints and Best Practices

* Focus on **ideas**, not implementation details
* Assume your audience understands Python and ML basics
* Use diagrams over equations
* Avoid reading slides verbatim
* Practice explaining the paper *without jargon*


This assignment is designed to help you **think like a researcher and systems designer**, not just a tool user.
Choose wisely, read deeply, and present with clarity.
